{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project\n",
    "\n",
    "Introduction:- You have been asked to provide consultation to Ms Alexandra Kolishnyick (a.k.a. Alexa), for her investment management. As an expert investment analyst, your task is to analyze a portfolio of stocks, compare performance against the S&P500 market index and create price prediction using appropriate machine learning techniques. Based on the results, you are expected to suggest Ms Alexa about the prospect of the analyzed stocks and their potential for investment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aviation Indsutry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data set for all the aviation industry\n",
    "aal = pd.read_csv('AAL.csv')\n",
    "aal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for column data types and null values\n",
    "aal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=aal['Date'],open=aal['Open'],high=aal['High'],\n",
    "                low=aal['Low'],\n",
    "                close=aal['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the columns\n",
    "aal = aal.rename(columns={'Adj Close':'American Airline Group'})\n",
    "aal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the dataset into require columns for further analysis\n",
    "aal = aal[['Date','American Airline Group']]\n",
    "aal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##converting the date to datetime format\n",
    "aal['Date'] = pd.to_datetime(aal['Date'])\n",
    "aal.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the date as the index\n",
    "aal = aal.set_index('Date')\n",
    "aal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading the second file from the aviation industry\n",
    "alk = pd.read_csv('ALK.csv')\n",
    "alk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for column data types and null values\n",
    "alk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the null values\n",
    "alk = alk.dropna(axis=0,how='any')\n",
    "alk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=alk['Date'],\n",
    "                open=alk['Open'],\n",
    "                high=alk['High'],\n",
    "                low=alk['Low'],\n",
    "                close=alk['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the required columns for further analysis\n",
    "alk = alk.rename(columns={'Adj Close':'Alaska Airline Group'})\n",
    "alk = alk[['Date','Alaska Airline Group']]\n",
    "alk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##converting the date to datetime format\n",
    "alk['Date'] = pd.to_datetime(alk['Date'])\n",
    "alk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the date as the index\n",
    "alk = alk.set_index('Date')\n",
    "alk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading the third file from the aviation industry\n",
    "ha = pd.read_csv('HA.csv')\n",
    "ha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for column data types and null values\n",
    "ha.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the null values\n",
    "ha = ha.dropna(axis=0,how='any')\n",
    "ha.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=ha['Date'],\n",
    "                open=ha['Open'],\n",
    "                high=ha['High'],\n",
    "                low=ha['Low'],\n",
    "                close=ha['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "ha = ha.rename(columns={'Adj Close':'Hawaiian Holdings, Inc.'})\n",
    "ha = ha[['Date','Hawaiian Holdings, Inc.']]\n",
    "ha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha['Date'] = pd.to_datetime(ha['Date'])\n",
    "ha.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ha = ha.set_index('Date')\n",
    "ha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining all the stocks from aviation industry into single frame\n",
    "frames = [aal,alk,ha]\n",
    "aviation = pd.concat(frames,axis=1)\n",
    "aviation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the daily return in the aviation group\n",
    "aviation_daily_returns = aviation.pct_change()\n",
    "aviation_daily_returns = aviation_daily_returns.dropna(axis=0)\n",
    "aviation_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Avg Daily Return (%)')\n",
    "(aviation_daily_returns.mean()*100).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = aviation_daily_returns.corr()\n",
    "#plot correlation and avg daily return\n",
    "sns.heatmap(correlation,linewidths=2.0,cmap=\"YlGnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All the three airlines have more or less same coorelation coefficient with each other, indicating the more or less movement throughout the period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finance Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading all the stocks in the finance industry\n",
    "cs = pd.read_csv('CS.csv')\n",
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for column data types and null values\n",
    "cs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values from the dataset\n",
    "cs = cs.dropna(axis=0,how='any')\n",
    "cs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=cs['Date'],\n",
    "                open=cs['Open'],\n",
    "                high=cs['High'],\n",
    "                low=cs['Low'],\n",
    "                close=cs['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the required columns for further analysis\n",
    "cs = cs.rename(columns={'Adj Close':'Credit Suisse Group'})\n",
    "cs = cs[['Date','Credit Suisse Group']]\n",
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dates into datetime format\n",
    "cs['Date'] = pd.to_datetime(cs['Date'])\n",
    "cs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = cs.set_index('Date')\n",
    "cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the second data from the finance industry\n",
    "db = pd.read_csv('DB.csv')\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for column data types and null values\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values from the dataset\n",
    "db = db.dropna(axis=0,how='any')\n",
    "db.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=db['Date'],\n",
    "                open=db['Open'],\n",
    "                high=db['High'],\n",
    "                low=db['Low'],\n",
    "                close=db['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "db = db.rename(columns={'Adj Close':'Deutsche Bank'})\n",
    "db = db[['Date','Deutsche Bank']]\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "db['Date'] = pd.to_datetime(db['Date'])\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.set_index('Date')\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the third data from the finance industry\n",
    "gs = pd.read_csv('GS.csv')\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values from the dataset\n",
    "gs = gs.dropna(axis=0,how='any')\n",
    "gs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=gs['Date'],\n",
    "                open=gs['Open'],\n",
    "                high=gs['High'],\n",
    "                low=gs['Low'],\n",
    "                close=gs['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "gs = gs.rename(columns={'Adj Close':'Goldman Sachs'})\n",
    "gs = gs[['Date','Goldman Sachs']]\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "gs['Date'] = pd.to_datetime(gs['Date'])\n",
    "gs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gs.set_index('Date')\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## joining all the stocks from finance industry into single frame\n",
    "frames = [cs,db,gs]\n",
    "finance = pd.concat(frames,axis=1)\n",
    "finance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finance.index.max() - finance.index.min())\n",
    "#print(aviation.index.max() - aviation.index.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is mismatch of time period between finance and aviaition industry. The dates should be selected which are common to all the industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### taking the exact number of dates as present in the aviaition industry\n",
    "finance = finance.loc['01-10-2010':]\n",
    "finance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The time period looks the same now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the daily return in the aviation group\n",
    "finance_daily_returns = finance.pct_change()\n",
    "finance_daily_returns = finance_daily_returns.dropna(axis=0)\n",
    "finance_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Avg Daily Return (%)')\n",
    "(finance_daily_returns.mean()*100).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import api as sm\n",
    "correlation = finance_daily_returns.corr()\n",
    "#plot correlation\n",
    "sns.heatmap(correlation,linewidths=2.0,cmap=\"YlGnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Credit Suisse and Deutche bank daily return per day have a positive coorelation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pharmaceutical Industry\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the first date set in phrama industry\n",
    "bhc = pd.read_csv('BHC.csv')\n",
    "bhc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "bhc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values\n",
    "bhc = bhc.dropna(axis=0,how='any')\n",
    "bhc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=bhc['Date'],\n",
    "                open=bhc['Open'],\n",
    "                high=bhc['High'],\n",
    "                low=bhc['Low'],\n",
    "                close=bhc['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "bhc = bhc.rename(columns={'Adj Close':'Bausch Health Companies'})\n",
    "bhc = bhc[['Date','Bausch Health Companies']]\n",
    "bhc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "bhc['Date'] = pd.to_datetime(bhc['Date'])\n",
    "bhc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhc = bhc.set_index('Date')\n",
    "bhc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data for the next stock in phrama industry\n",
    "jnj = pd.read_csv('JNJ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj['Company'] = 'Johnson & Johnson'\n",
    "jnj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj = jnj.dropna(axis=0,how='any')\n",
    "jnj.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=jnj['Date'],\n",
    "                open=jnj['Open'],\n",
    "                high=jnj['High'],\n",
    "                low=jnj['Low'],\n",
    "                close=jnj['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "jnj = jnj.rename(columns={'Adj Close':'Johnson & Johnson'})\n",
    "jnj = jnj[['Date','Johnson & Johnson']]\n",
    "jnj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "jnj['Date'] = pd.to_datetime(jnj['Date'])\n",
    "jnj.info()#check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj = jnj.set_index('Date')\n",
    "jnj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the third file from the pharma industry\n",
    "mrk = pd.read_csv('MRK.csv')\n",
    "mrk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values \n",
    "mrk = mrk.dropna(axis=0,how='any')\n",
    "mrk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=mrk['Date'],\n",
    "                open=mrk['Open'],\n",
    "                high=mrk['High'],\n",
    "                low=mrk['Low'],\n",
    "                close=mrk['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "mrk = mrk.rename(columns={'Adj Close':'Merck'})\n",
    "mrk = mrk[['Date','Merck']]\n",
    "mrk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "mrk['Date'] = pd.to_datetime(mrk['Date'])\n",
    "mrk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrk = mrk.set_index('Date')\n",
    "mrk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining all the pharmas stocks together\n",
    "frames = [bhc,jnj,mrk]\n",
    "healthcare_Pharma = pd.concat(frames,axis=1)\n",
    "healthcare_Pharma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the daily return in the aviation group\n",
    "healthcare_Pharma_daily_returns = healthcare_Pharma.pct_change()\n",
    "healthcare_Pharma_daily_returns = healthcare_Pharma_daily_returns.dropna(axis=0)\n",
    "healthcare_Pharma_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visulaizing the avg daily returns from the industry\n",
    "plt.ylabel('Avg Daily Return (%)')\n",
    "(healthcare_Pharma_daily_returns.mean()*100).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import api as sm\n",
    "correlation = healthcare_Pharma_daily_returns.corr()\n",
    "#plot correlation\n",
    "sns.heatmap(correlation,linewidths=2.0,cmap=\"YlGnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- Johnson & Johnson and Mereck have both showed weak correlation with Bausch Health Company. The sudden drop for the BHC during the end of 2015 could be the result of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech Industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the first file from the tech industry\n",
    "apple = pd.read_csv('AAPL.csv')\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping any null values in the dataset\n",
    "apple = apple.dropna(axis=0,how='any')\n",
    "apple.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=apple['Date'],\n",
    "                open=apple['Open'],\n",
    "                high=apple['High'],\n",
    "                low=apple['Low'],\n",
    "                close=apple['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset for further analysis\n",
    "apple = apple.rename(columns={'Adj Close':'Apple'})\n",
    "apple = apple[['Date','Apple']]\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "apple['Date'] = pd.to_datetime(apple['Date'])\n",
    "apple.info()\n",
    "\n",
    "apple = apple.set_index('Date')\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the second file from the tech industry\n",
    "amazon = pd.read_csv('AMZN.csv')\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values from the dataset\n",
    "amazon = amazon.dropna(axis=0,how='any')\n",
    "amazon.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=amazon['Date'],\n",
    "                open=amazon['Open'],\n",
    "                high=amazon['High'],\n",
    "                low=amazon['Low'],\n",
    "                close=amazon['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset for further analysis\n",
    "amazon = amazon.rename(columns={'Adj Close':'Amazon'})\n",
    "amazon = amazon[['Date','Amazon']]\n",
    "\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "amazon['Date'] = pd.to_datetime(amazon['Date'])\n",
    "amazon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = amazon.set_index('Date')\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the third file from the tech industry\n",
    "google = pd.read_csv('GOOG.csv')\n",
    "\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the null values from the data\n",
    "google = google.dropna(axis=0,how='any')\n",
    "google.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=google['Date'],\n",
    "                open=google['Open'],\n",
    "                high=google['High'],\n",
    "                low=google['Low'],\n",
    "                close=google['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for further analysis\n",
    "google = google.rename(columns={'Adj Close':'Google'})\n",
    "google = google[['Date','Google']]\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the date into datetime format\n",
    "google['Date'] = pd.to_datetime(google['Date'])\n",
    "google.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google = google.set_index('Date')\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all the stocks together\n",
    "frames = [apple,amazon,google]\n",
    "technology = pd.concat(frames,axis=1)\n",
    "technology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the daily return in the aviation group\n",
    "technology_daily_returns = technology.pct_change()\n",
    "technology_daily_returns = technology_daily_returns.dropna(axis=0)\n",
    "technology_daily_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Avg Daily Return (%)')\n",
    "(technology_daily_returns.mean()*100).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = technology_daily_returns.corr()\n",
    "#plot correlation\n",
    "sns.heatmap(correlation,linewidths=2.0,cmap=\"YlGnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- All the tech giants are closely related to each other doing well in the stock market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=Red> Market S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the market data\n",
    "snp = pd.read_csv('S&P500.csv')\n",
    "snp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the highs and lows in the given period\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=snp['Date'],\n",
    "                open=snp['Open'],\n",
    "                high=snp['High'],\n",
    "                low=snp['Low'],\n",
    "                close=snp['Close'])])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- The market was continouly growing from 2010 to 2020 until the covid crisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns for further analysis\n",
    "snp = snp.rename(columns={'Adj Close':'S&P'})\n",
    "snp = snp[['Date','S&P']]\n",
    "snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp['Date'] = pd.to_datetime(snp['Date'])\n",
    "snp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp = snp.set_index('Date')\n",
    "snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combining the adj.closing price of all the stocks with the market adj closing price \n",
    "frames = [aviation,healthcare_Pharma,finance,technology,snp]\n",
    "final_data = pd.concat(frames,axis=1)\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##time series plot for all the stocks industry wise\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(2,2,1)\n",
    "final_data['American Airline Group'].plot(label = 'American Airline Group',figsize = (20,10))\n",
    "final_data['Alaska Airline Group'].plot(label = 'Alaska Airline Group')\n",
    "final_data['Hawaiian Holdings, Inc.'].plot(label = 'Hawaiian Holdings, Inc')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices within Aviation Industry')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "final_data['Bausch Health Companies'].plot(label = 'BHC', figsize = (20,10))\n",
    "final_data['Johnson & Johnson'].plot(label = 'Johnson & Johnson')\n",
    "final_data['Merck'].plot(label = 'Merck')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices within Pharma Industry')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "final_data['Apple'].plot(label = 'Apple', figsize = (20,10))\n",
    "final_data['Google'].plot(label = 'Google')\n",
    "final_data['Amazon'].plot(label = 'Amazon')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices within Tech Industry')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "final_data['Goldman Sachs'].plot(label = 'Goldman Sachs', figsize = (20,10))\n",
    "final_data['Credit Suisse Group'].plot(label = 'Credit Suisse Group')\n",
    "final_data['Deutsche Bank'].plot(label = 'Deutsche Bank')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices within Finance Industry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences\n",
    "\n",
    "- Avaition Group shows high growth during the initial period and with time the shares of each stock in the industry. The reason could be the affect of the pandemic during lockdown when all the transportation was halted.\n",
    "- Phrmaceutical Industry especially Johnson & Johnson and Mereck have shown an upward trend during the period. This upward movemenet resulted due to covid as these companies played a significant role in fighting covid, with rolling out vaccines and medication to the general public. It is interesting to note that the Bausch Health Companies stock fell dramatically at the end of 2015,  \n",
    "- Tech industry have shown a significant growth within the time period, Amazon and Google being the biggest player.\n",
    "- Credit Suisse and Deutsche Bank have significanlty show a down trend with Goldman Sachs being a more dominant player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##time series plot for all the stocks with market S&P\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "final_data['American Airline Group'].plot(label = 'AAL',figsize = (20,10))\n",
    "final_data['Alaska Airline Group'].plot(label = 'ALG')\n",
    "final_data['Hawaiian Holdings, Inc.'].plot(label = 'HHI')\n",
    "final_data['Bausch Health Companies'].plot(label = 'BHC', figsize = (20,10))\n",
    "final_data['Johnson & Johnson'].plot(label = 'J&J')\n",
    "final_data['Merck'].plot(label = 'Merck')\n",
    "final_data['Apple'].plot(label = 'Apple', figsize = (20,10))\n",
    "final_data['Google'].plot(label = 'Google')\n",
    "final_data['Amazon'].plot(label = 'Amazon')\n",
    "final_data['Goldman Sachs'].plot(label = 'Goldman Sachs', figsize = (20,10))\n",
    "final_data['Credit Suisse Group'].plot(label = 'Credit Suisse Group')\n",
    "final_data['Deutsche Bank'].plot(label = 'Deutsche Bank')\n",
    "final_data['S&P'].plot(label='S&P')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration for critical metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the daily return from each stock \n",
    "return_stocks = final_data.pct_change()\n",
    "return_stocks.head(5)\n",
    "\n",
    "return_stocks = return_stocks.dropna(axis=0)\n",
    "return_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation = return_stocks.corr()\n",
    "#plot correlation\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.heatmap(correlation,linewidths=0.1,cmap=\"YlGnBu\",annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferences\n",
    "- Finance stock are failry very correlated with the S&P market index than any other industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the normal distribution for the adj closing prices\n",
    "def histogram(data):\n",
    "    for i in data:\n",
    "        data[i].hist(bins = 50, figsize = (10,5)) \n",
    "        plt.xlabel(i)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "histogram(return_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(return_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferences\n",
    "\n",
    "- Credit Suisse gives the perfect curve distribution from all the other stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding other metrics related to adj.closing price\n",
    "portfolio_stocks = return_stocks.describe().T\n",
    "portfolio_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the redundant columns\n",
    "portfolio_stocks.drop(columns=['count','25%','75%'],inplace=True)\n",
    "\n",
    "portfolio_stocks.rename(columns={'50%':'median','mean':'avg daily return','std':'risk'},inplace=True)\n",
    "\n",
    "#portfolio_stocks = portfolio_stocks*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the annulized return\n",
    "portfolio_stocks['annualized return'] = portfolio_stocks['avg daily return']*252\n",
    "portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the annulaized risk\n",
    "portfolio_stocks['annualized risk'] = portfolio_stocks['risk']* np.sqrt(252)\n",
    "portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing all the metrics with bar charts for all the stocks\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,1)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=portfolio_stocks.index, y='avg daily return', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Avg Daily Return')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,2)\n",
    "sns.barplot(x=portfolio_stocks.index, y='risk', data = portfolio_stocks, palette='summer')\n",
    "plt.title('Risk Associated with each Stocks')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,3)\n",
    "sns.barplot(x=portfolio_stocks.index, y='min', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Min change in daily rates')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Min percent change')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,4)\n",
    "sns.barplot(x=portfolio_stocks.index, y='median', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Median change in daily rates')\n",
    "plt.title('Median')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,4)\n",
    "sns.barplot(x=portfolio_stocks.index, y='max', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Max percent change in Stock Prices')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,5)\n",
    "sns.barplot(x=portfolio_stocks.index, y='annualized return', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices with annualized return')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(3,2,6)\n",
    "sns.barplot(x=portfolio_stocks.index, y='annualized risk', data = portfolio_stocks, palette='summer')\n",
    "plt.ylabel('Adj Closing Price')\n",
    "plt.title('Stock Prices within Finance Industry')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return VS Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "plt.xticks(rotation=90)\n",
    "color = 'tab:green'\n",
    "ax1.set_title('Annualized Return vs Risk', fontsize=16)\n",
    "ax1.set_xlabel('Stocks', fontsize=16)\n",
    "ax1.set_ylabel('Annualized Return', fontsize=16, color=color)\n",
    "ax2 = sns.barplot(x=portfolio_stocks.index, y='annualized return', data = portfolio_stocks, palette='summer')\n",
    "ax1.tick_params(axis='y')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('annualized risk', fontsize=16, color=color)\n",
    "ax2 = sns.lineplot(x=portfolio_stocks.index,y='annualized risk', data = portfolio_stocks, sort=False, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- Annulaized return for Credit Suisee Group and Deutsche bank are negative and show a huge risk. Hence they should be avoided\n",
    "- Annualized risk for Johnson&Johnson and Merck and quite low with significant return\n",
    "- Highest return can be seen in tech industry with Amzon being the most risky and high return stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'ticks', font_scale = 1.25)\n",
    "sns.pairplot(return_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferences\n",
    "\n",
    "- Based on annulaized risk and return and keeping in my mind the behaviour of our customer, we decided to make the portfolio based on minimum risk which maximize profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing the stocks according to our client behaviour and weighting them\n",
    "my_portfolio = return_stocks[['Johnson & Johnson','Merck','Google','Apple']]\n",
    "my_portfolio.head()\n",
    "initial_weight = np.array([0.30, 0.30, 0.20,0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns_Portfolio_mean =  my_portfolio.mean()\n",
    "print(daily_returns_Portfolio_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio daily returns\n",
    "my_portfolio['Portfolio_Daily_Return'] = my_portfolio.dot(initial_weight)\n",
    "\n",
    "my_portfolio.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative return from the portfolio\n",
    "Cumulative_returns_daily = (1+my_portfolio).cumprod()\n",
    "Cumulative_returns_daily.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Portfolio Return = Weighted average of return from each stock\n",
    "allocated_daily_returns = (initial_weight * daily_returns_Portfolio_mean)\n",
    "portfolio_return = np.sum(allocated_daily_returns)\n",
    "print(portfolio_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_portfolio['Portfolio_Daily_Return'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "Cumulative_returns_daily['Portfolio_Daily_Return'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix for the portfolio\n",
    "\n",
    "# Removing the last column (Portfolio_Daily_Return) from our calculation.\n",
    "covariance_portfolio = my_portfolio.iloc[:,:-1]\n",
    "covariance_portfolio = (covariance_portfolio.cov())*252\n",
    "\n",
    "covariance_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the matrix operations mentioned in the image above\n",
    "portfolio_variance = np.dot(initial_weight.T,np.dot(covariance_portfolio, initial_weight))\n",
    "print(\"------portfolio_variance------\",portfolio_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation (risk of portfolio)\n",
    "portfolio_risk = np.sqrt(portfolio_variance)\n",
    "portfolio_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the risk free rate is zero\n",
    "Sharpe_Ratio = my_portfolio['Portfolio_Daily_Return'].mean() / my_portfolio['Portfolio_Daily_Return'].std()\n",
    "Sharpe_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the annual sharpe ratio\n",
    "Annualised_Sharpe_Ratio = (252**0.5)*Sharpe_Ratio\n",
    "Annualised_Sharpe_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting each stock against the S&P \n",
    "def scatter(data,a,b):\n",
    "    beta, alpha = np.polyfit(data[a], data[b], 1)\n",
    "    return_stocks.plot(kind = 'scatter', x = a, y = b,figsize=(8, 8))\n",
    "    plt.plot(return_stocks[a], beta * return_stocks[a] + alpha, '--', color = 'r')\n",
    "    plt.show()\n",
    "# Straight line equation with alpha and beta parameters \n",
    "# Straight line equation is y = beta * rm + alph\n",
    "\n",
    "\n",
    "scatter(return_stocks,'S&P','Johnson & Johnson')\n",
    "scatter(return_stocks,'S&P','Merck')\n",
    "scatter(return_stocks,'S&P','Google')\n",
    "scatter(return_stocks,'S&P','Apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Using CAPM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the library\n",
    "import statsmodels.api as sm\n",
    "# Calculating the daily return for portfolio stock \n",
    "portfolio_stocks_final = final_data.pct_change()*100\n",
    "portfolio_stocks_final.head(5)\n",
    "\n",
    "portfolio_stocks_final = portfolio_stocks_final.dropna(axis=0)\n",
    "portfolio_stocks_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(portfolio_stocks_final['S&P'], portfolio_stocks_final['Johnson & Johnson'], 1)\n",
    "beta\n",
    "alpha\n",
    "\n",
    "rf = 0.75\n",
    "rm = portfolio_stocks_final['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected_returns_portfolio = pd.DataFrame({'Stocks':'Johnson & Johnson','Expected Return':[er]})\n",
    "Expected_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(return_stocks['S&P'], return_stocks['Merck'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = 0.75\n",
    "rm = portfolio_stocks_final['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Merck','Expected Return':[er]})\n",
    "frames = [Expected_returns_portfolio,temp]\n",
    "Expected_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(portfolio_stocks_final['S&P'], portfolio_stocks_final['Apple'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected return\n",
    "rf = 0.75\n",
    "rm = portfolio_stocks_final['S&P'].mean() * 252\n",
    "er = rf+ beta*(rm-rf)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Apple','Expected Return':[er]})\n",
    "frames = [Expected_returns_portfolio,temp]\n",
    "Expected_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(portfolio_stocks_final['S&P'], portfolio_stocks_final['Google'], 1)\n",
    "\n",
    "#expected return\n",
    "rf = 0.75\n",
    "rm = portfolio_stocks_final['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Google','Expected Return':[er]})\n",
    "frames = [Expected_returns_portfolio,temp]\n",
    "Expected_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erp = Expected_returns_portfolio['Expected Return'].tolist()\n",
    "erp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##portfolio return\n",
    "my_portfolio = portfolio_stocks_final[['Johnson & Johnson','Merck','Apple','Google']]\n",
    "my_portfolio.head()\n",
    "initial_weight = np.array([0.30, 0.30, 0.20,0.20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ER_portfolio_all = round(sum(erp * initial_weight),3)\n",
    "print('Expected Return Based on CAPM for the portfolio  is {}%\\n'.format(ER_portfolio_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference:- \n",
    "\n",
    "- So the market return is around 12 % and the portfolio weighted return is coming around 11% which is not bad, considering the return and risk of the portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets use johnson & johnson stock to forecast the fututre values\n",
    "johnson = final_data.iloc[:,4:5]\n",
    "johnson.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the dateset for forecast\n",
    "johnson['Date'] = pd.to_datetime(johnson['Date']).dt.to_period('m')\n",
    "johnson = johnson.set_index('Date')\n",
    "johnson = johnson.groupby(['Date']).sum()\n",
    "johnson.sort_index(inplace=True)\n",
    "\n",
    "johnson = johnson.to_timestamp()\n",
    "\n",
    "\n",
    "johnson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = johnson[0:train_len] \n",
    "test = johnson[train_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition and multiplicative decomposition to understand the trend and seasonality in the data\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(johnson['Johnson & Johnson'], model='additive') # additive seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(johnson[\"Johnson & Johnson\"], model='multiplicative') # multiplicative seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deciding to choose additive model will be used as individual components can be added to get the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let us prepare all the data for stock for forcasting \n",
    "##preparing the data for merck forecasting\n",
    "merck = final_data.iloc[:,5:6]\n",
    "merck.reset_index(inplace=True)\n",
    "merck.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data for forecasting\n",
    "merck['Date'] = pd.to_datetime(merck['Date']).dt.to_period('m')\n",
    "\n",
    "merck = merck.set_index('Date')\n",
    "\n",
    "\n",
    "merck = merck.groupby(['Date']).sum()\n",
    "merck.sort_index(inplace=True)\n",
    "\n",
    "merck = merck.to_timestamp()\n",
    "\n",
    "\n",
    "merck.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = merck[0:train_len] \n",
    "test = merck[train_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition and multiplicative decomposition\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(merck['Merck'], model='additive') # additive seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(merck[\"Merck\"], model='multiplicative') # multiplicative seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deciding to choose additive model will be used as individual components can be added to get the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decomposing the third stock in the expected portfolio\n",
    "##preparing the data for amazon forecasting\n",
    "google = final_data.iloc[:,11:12]\n",
    "google.reset_index(inplace=True)\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google['Date'] = pd.to_datetime(google['Date']).dt.to_period('m')\n",
    "\n",
    "google = google.set_index('Date')\n",
    "\n",
    "\n",
    "google = google.groupby(['Date']).sum()\n",
    "google.sort_index(inplace=True)\n",
    "\n",
    "google = google.to_timestamp()\n",
    "\n",
    "\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = google[0:train_len] \n",
    "test = google[train_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition and multiplicative decomposition\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(google['Google'], model='additive') # additive seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(google[\"Google\"], model='multiplicative') # multiplicative seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deciding to choose additive model will be used as individual components can be added to get the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##decomposing the third stock in the expected portfolio\n",
    "##preparing the data for merck forecasting\n",
    "apple = final_data.iloc[:,9:10]\n",
    "apple.reset_index(inplace=True)\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple['Date'] = pd.to_datetime(apple['Date']).dt.to_period('m')\n",
    "\n",
    "apple = apple.set_index('Date')\n",
    "\n",
    "\n",
    "apple = apple.groupby(['Date']).sum()\n",
    "apple.sort_index(inplace=True)\n",
    "\n",
    "apple = apple.to_timestamp()\n",
    "\n",
    "\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = apple[0:train_len] \n",
    "test = apple[train_len:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#addition and multiplicative decomposition\n",
    "from pylab import rcParams\n",
    "import statsmodels.api as sm\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(apple['Apple'], model='additive') # additive seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(apple[\"Apple\"], model='multiplicative') # multiplicative seasonal index\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferences\n",
    "- Deciding to choose additive model will be used as individual components can be added to get the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationary Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adf test to check if the time series are stationary or not\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(johnson['Johnson & Johnson'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "- Augmented Dickey-Fuller (ADF) Test proposes that Null Hypothesis (H0): The series is not stationary if pvalue>0.05 and Alternate Hypothesis (H1): The series is stationary if pvalue0.05\n",
    "- So the null hypothesis is fail to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box-cox transformation to make the series stationary by removing the variance\n",
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(johnson['Johnson & Johnson'], lmbda=0), index = johnson.index)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox, label='After Box Cox tranformation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differencing to remove trend to make the mean constant\n",
    "data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), johnson.index)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform and differencing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boxcox_diff.dropna(inplace=True)\n",
    "adf_test = adfuller(data_boxcox_diff)\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The p-value is nown less than 0.05, so the null hypothesis is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = johnson[0:train_len] \n",
    "test = johnson[train_len:] \n",
    "train_data_boxcox = data_boxcox[:train_len]\n",
    "test_data_boxcox = data_boxcox[train_len:]\n",
    "train_data_boxcox_diff = data_boxcox_diff[:train_len-1]\n",
    "test_data_boxcox_diff = data_boxcox_diff[train_len-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to find the correct p,d,q value from autoarima \n",
    "## sarima model to forecast\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "stepwise_fit = auto_arima(train_data_boxcox_diff, start_p = 0, start_q = 0,\n",
    "                          max_p = 10, max_q = 10,\n",
    "                          start_P = 0, seasonal = True,\n",
    "                          d = None, D = 1, trace = True,\n",
    "                          error_action ='ignore',   # we don't want to know if an order does not work\n",
    "                          suppress_warnings = True,  # we don't want convergence warnings\n",
    "                          stepwise = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto regression model to forecast\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "model = ARIMA(train_data_boxcox_diff, order=(1, 0, 0)) \n",
    "model_fit = model.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_ar = data_boxcox_diff.copy()\n",
    "y_hat_ar['ar_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\n",
    "y_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox_diff'].cumsum()\n",
    "y_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_hat_ar['ar_forecast'] = np.exp(y_hat_ar['ar_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(train['Johnson & Johnson'], label='Train')\n",
    "plt.plot(test['Johnson & Johnson'], label='Test')\n",
    "plt.plot(y_hat_ar['ar_forecast'][test.index.min():], label='Auto regression forecast')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Auto Regression Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test['Johnson & Johnson'], y_hat_ar['ar_forecast'][test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['Johnson & Johnson']-y_hat_ar['ar_forecast'][test.index.min():])/test['Johnson & Johnson'])*100,2)\n",
    "\n",
    "tempResults = pd.DataFrame({'Method':['Autoregressive (AR) method'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "tempResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## moving average model to forecast\n",
    "model = ARIMA(train_data_boxcox_diff, order=(0, 0, 1)) \n",
    "model_fit = model.fit()\n",
    "print(model_fit.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_ma = data_boxcox_diff.copy()\n",
    "y_hat_ma['ma_forecast_boxcox_diff'] = model_fit.predict(data_boxcox_diff.index.min(), data_boxcox_diff.index.max())\n",
    "y_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox_diff'].cumsum()\n",
    "y_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox'].add(data_boxcox[0])\n",
    "y_hat_ma['ma_forecast'] = np.exp(y_hat_ma['ma_forecast_boxcox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(train['Johnson & Johnson'], label='Train')\n",
    "plt.plot(test['Johnson & Johnson'], label='Test')\n",
    "plt.plot(y_hat_ma['ma_forecast'][test.index.min():], label='Moving average forecast')\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test['Johnson & Johnson'], y_hat_ma['ma_forecast'][test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['Johnson & Johnson']-y_hat_ma['ma_forecast'][test.index.min():])/test['Johnson & Johnson'])*100,2)\n",
    "\n",
    "tempResults2 = pd.DataFrame({'Method':['Moving Average (MA) method'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "tempResults2\n",
    "frames = [tempResults,tempResults2]\n",
    "results = pd.concat(frames,axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarima model to forecast\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "  \n",
    "model = SARIMAX(johnson['Johnson & Johnson'], order = (1, 1, 1), seasonal_order =(2, 0, 2, 12))\n",
    "  \n",
    "result = model.fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "  \n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end,\n",
    "                             typ = 'levels').rename(\"Predictions\")\n",
    "\n",
    "  \n",
    "# plot predictions and actual values\n",
    "predictions.plot(legend = True)\n",
    "train['Johnson & Johnson'].plot(legend = True,label='Train')\n",
    "test['Johnson & Johnson'].plot(legend = True,label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Calculate root mean squared error\n",
    "rmse = np.sqrt(mean_squared_error(test['Johnson & Johnson'], predictions[test.index.min():])).round(2)\n",
    "# Calculate mean absolute percentage error\n",
    "mape = np.round(np.mean(np.abs(test['Johnson & Johnson']-predictions[test.index.min():])/test['Johnson & Johnson'])*100,2)\n",
    "tempResults = pd.DataFrame({'Method':['SARIMA - Johnson & Johnson'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "results = pd.concat([results, tempResults])\n",
    "results = results[['Method', 'RMSE', 'MAPE']]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Sarima model the forecast generated has the least RMSE and MAPE errors, so will continue with this model to forecast other stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## future prediction through sarima for 12 months\n",
    "model = model = SARIMAX(johnson['Johnson & Johnson'], \n",
    "                        order = (1, 1, 1), \n",
    "                        seasonal_order =(2, 0, 2, 12))\n",
    "result = model.fit()\n",
    "  \n",
    "\n",
    "# Forecast for the next 3 years\n",
    "forecast_johnson = result.predict(start = len(johnson), \n",
    "                          end = (len(johnson)-1) + 1 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "  \n",
    "# Plot the forecast values\n",
    "johnson['Johnson & Johnson'].plot(figsize = (12, 5), legend = True)\n",
    "forecast_johnson.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_johnson.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mereck forecasting\n",
    "# using adf test to check if the time series are stationary or not\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(merck['Merck'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- Augmented Dickey-Fuller (ADF) Test proposes that Null Hypothesis (H0): The series is not stationary if pvalue>0.05 and Alternate Hypothesis (H1): The series is stationary if pvalue0.05\n",
    "- So the null hypothesis is fail to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##mereck\n",
    "#box-cox transformation\n",
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(merck['Merck'], lmbda=0), index = merck.index)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox, label='After Box Cox tranformation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#differencing to remove trend\n",
    "data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), merck.index)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform and differencing')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf\n",
    "data_boxcox_diff.dropna(inplace=True)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the p and q values come out to be 3 and 1 as in ACF a total number of 3 nodes are reaching out of critical region and \n",
    "- in PCF just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = merck[0:train_len] \n",
    "test = merck[train_len:] \n",
    "train_data_boxcox = data_boxcox[:train_len]\n",
    "test_data_boxcox = data_boxcox[train_len:]\n",
    "train_data_boxcox_diff = data_boxcox_diff[:train_len-1]\n",
    "test_data_boxcox_diff = data_boxcox_diff[train_len-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "model = SARIMAX(merck['Merck'],order = (3, 1, 1),seasonal_order =(2, 0, 2, 12))\n",
    "result = model.fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "  \n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end,\n",
    "                             typ = 'levels').rename(\"Predictions\")\n",
    "\n",
    "  \n",
    "# plot predictions and actual values\n",
    "predictions.plot(legend = True)\n",
    "train['Merck'].plot(legend = True,label='Train')\n",
    "test['Merck'].plot(legend = True,label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test['Merck'], predictions[test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['Merck']-predictions[test.index.min():])/test['Merck'])*100,2)\n",
    "\n",
    "tempResults = pd.DataFrame({'Method':['SARIMA - Merck'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "results = pd.concat([results, tempResults])\n",
    "results = results[['Method', 'RMSE', 'MAPE']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcast into the future 12 months\n",
    "model = model = SARIMAX(merck['Merck'], \n",
    "                        order = (1, 1, 1), \n",
    "                        seasonal_order =(2, 0, 2, 12))\n",
    "result = model.fit()\n",
    "  \n",
    "\n",
    "# Forecast for the next 3 years\n",
    "forecast_merck = result.predict(start = len(merck), \n",
    "                          end = (len(merck)-1) + 1 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "  \n",
    "# Plot the forecast values\n",
    "merck['Merck'].plot(figsize = (12, 5), legend = True)\n",
    "forecast_merck.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_merck.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Google Forecast\n",
    "# using adf test to check if the time series are stationary or not\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(google['Google'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- Augmented Dickey-Fuller (ADF) Test proposes that Null Hypothesis (H0): The series is not stationary if pvalue>0.05 and Alternate Hypothesis (H1): The series is stationary if pvalue0.05\n",
    "- So the null hypothesis is fail to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##google\n",
    "#box-cox transformation\n",
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(google['Google'], lmbda=0), index = google.index)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox, label='After Box Cox tranformation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#differencing to remove trend\n",
    "data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), google.index)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform and differencing')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf\n",
    "data_boxcox_diff.dropna(inplace=True)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the p and q values come out to be 3 and 4 as in ACF a total number of 3 nodes are reaching out of critical region and \n",
    "- in PCF just four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = google[0:train_len] \n",
    "test = google[train_len:] \n",
    "train_data_boxcox = data_boxcox[:train_len]\n",
    "test_data_boxcox = data_boxcox[train_len:]\n",
    "train_data_boxcox_diff = data_boxcox_diff[:train_len-1]\n",
    "test_data_boxcox_diff = data_boxcox_diff[train_len-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "model = SARIMAX(google['Google'],order = (3, 1, 4),seasonal_order =(1,0,1, 12))\n",
    "  \n",
    "result = model.fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "  \n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end,\n",
    "                             typ = 'levels').rename(\"Predictions\")\n",
    "\n",
    "  \n",
    "# plot predictions and actual values\n",
    "plt.figure(figsize=(12,4))\n",
    "predictions.plot(legend = True)\n",
    "train['Google'].plot(legend = True,label='Train')\n",
    "test['Google'].plot(legend = True,label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test['Google'], predictions[test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['Google']-predictions[test.index.min():])/test['Google'])*100,2)\n",
    "\n",
    "tempResults = pd.DataFrame({'Method':['SARIMA - Google'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "results = pd.concat([results, tempResults])\n",
    "results = results[['Method', 'RMSE', 'MAPE']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcast into the future 12 months\n",
    "model = model = SARIMAX(google['Google'], \n",
    "                        order = (3, 1,2), \n",
    "                        seasonal_order =(1, 0, 1, 12))\n",
    "result = model.fit()\n",
    "  \n",
    "\n",
    "# Forecast for the next 12 months\n",
    "forecast_google = result.predict(start = len(google), \n",
    "                          end = (len(google)-1) + 1 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "  \n",
    "# Plot the forecast values\n",
    "plt.figure(figsize=(12,4))\n",
    "train['Google'].plot(figsize = (12, 5), legend = True,label='Train')\n",
    "test['Google'].plot(figsize = (12, 5), legend = True,label='Test')\n",
    "forecast_google.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_google.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apple\n",
    "# using adf test to check if the time series are stationary or not\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(apple['Apple'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- Augmented Dickey-Fuller (ADF) Test proposes that Null Hypothesis (H0): The series is not stationary if pvalue>0.05 and Alternate Hypothesis (H1): The series is stationary if pvalue0.05\n",
    "- So the null hypothesis is fail to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google\n",
    "#box-cox transformation\n",
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(apple['Apple'], lmbda=0), index = apple.index)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox, label='After Box Cox tranformation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differencing to remove trend\n",
    "data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), apple.index)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform and differencing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf\n",
    "data_boxcox_diff.dropna(inplace=True)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So the p and q values come out to be 3 and 4 as in ACF a total number of 3 nodes are reaching out of critical region and in PCF just four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = apple[0:train_len] \n",
    "test = apple[train_len:] \n",
    "train_data_boxcox = data_boxcox[:train_len]\n",
    "test_data_boxcox = data_boxcox[train_len:]\n",
    "train_data_boxcox_diff = data_boxcox_diff[:train_len-1]\n",
    "test_data_boxcox_diff = data_boxcox_diff[train_len-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "model = SARIMAX(apple['Apple'],order = (3, 1, 4),seasonal_order =(1, 0, 1, 12))\n",
    "  \n",
    "result = model.fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "  \n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end,\n",
    "                             typ = 'levels').rename(\"Predictions\")\n",
    "\n",
    "  \n",
    "# plot predictions and actual values\n",
    "plt.figure(figsize=(12,4))\n",
    "predictions.plot(legend = True)\n",
    "train['Apple'].plot(legend = True,label='Train')\n",
    "test['Apple'].plot(legend = True,label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test['Apple'], predictions[test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['Apple']-predictions[test.index.min():])/test['Apple'])*100,2)\n",
    "\n",
    "tempResults = pd.DataFrame({'Method':['SARIMA - Apple'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "results = pd.concat([results, tempResults])\n",
    "results = results[['Method', 'RMSE', 'MAPE']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcast into the future 12 months\n",
    "model= SARIMAX(apple['Apple'], order = (3, 1, 4), seasonal_order =(1, 0,1, 12))\n",
    "result = model.fit()\n",
    "  \n",
    "\n",
    "# Forecast for the next 12 months\n",
    "forecast_apple = result.predict(start = len(apple), \n",
    "                          end = (len(apple)-1) + 1 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "  \n",
    "# Plot the forecast values\n",
    "plt.figure(figsize=(12,4))\n",
    "train['Apple'].plot(figsize = (12, 5), legend = True,label='Train')\n",
    "test['Apple'].plot(figsize = (12, 5), legend = True,label='Test')\n",
    "forecast_apple.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_apple.plot(legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets use johnson & johnson stock to forecast the fututre values\n",
    "snp = final_data.iloc[:,-1:]\n",
    "snp.reset_index(inplace=True)\n",
    "snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the dataset for forecast\n",
    "snp['Date'] = pd.to_datetime(snp['Date']).dt.to_period('m')\n",
    "snp = snp.set_index('Date')\n",
    "snp = snp.groupby(['Date']).sum()\n",
    "snp.sort_index(inplace=True)\n",
    "\n",
    "snp = snp.to_timestamp()\n",
    "\n",
    "\n",
    "snp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####S&P\n",
    "# using adf test to check if the time series are stationary or not\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "adf_test = adfuller(snp['S&P'])\n",
    "\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\n",
    "print('p-value: %f' % adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "- Augmented Dickey-Fuller (ADF) Test proposes that Null Hypothesis (H0): The series is not stationary if pvalue>0.05 and Alternate Hypothesis (H1): The series is stationary if pvalue0.05\n",
    "- So the null hypothesis is fail to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##amazon\n",
    "#box-cox transformation\n",
    "from scipy.stats import boxcox\n",
    "data_boxcox = pd.Series(boxcox(snp['S&P'], lmbda=0), index = snp.index)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox, label='After Box Cox tranformation')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#differencing to remove trend\n",
    "data_boxcox_diff = pd.Series(data_boxcox - data_boxcox.shift(), snp.index)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data_boxcox_diff, label='After Box Cox tranformation and differencing')\n",
    "plt.legend(loc='best')\n",
    "plt.title('After Box Cox transform and differencing')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acf\n",
    "data_boxcox_diff.dropna(inplace=True)\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_acf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plt.figure(figsize=(12,4))\n",
    "plot_pacf(data_boxcox_diff, ax=plt.gca(), lags = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "train_len = 105\n",
    "train = snp[0:train_len] \n",
    "test = snp[train_len:] \n",
    "train_data_boxcox = data_boxcox[:train_len]\n",
    "test_data_boxcox = data_boxcox[train_len:]\n",
    "train_data_boxcox_diff = data_boxcox_diff[:train_len-1]\n",
    "test_data_boxcox_diff = data_boxcox_diff[train_len-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "model = SARIMAX(snp['S&P'],order = (3, 1, 4),seasonal_order =(1, 1, 1, 12))\n",
    "  \n",
    "result = model.fit()\n",
    "print(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = len(train)\n",
    "end = len(train) + len(test) - 1\n",
    "  \n",
    "# Predictions for one-year against the test set\n",
    "predictions = result.predict(start, end).rename(\"Predictions\")\n",
    "\n",
    "  \n",
    "# plot predictions and actual values\n",
    "plt.figure(figsize=(12,4))\n",
    "predictions.plot(legend = True)\n",
    "train['S&P'].plot(legend = True,label='Train')\n",
    "test['S&P'].plot(legend = True,label='Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(test['S&P'], predictions[test.index.min():])).round(2)\n",
    "mape = np.round(np.mean(np.abs(test['S&P']-predictions[test.index.min():])/test['S&P'])*100,2)\n",
    "\n",
    "tempResults = pd.DataFrame({'Method':['SARIMA - S&P'], 'RMSE': [rmse],'MAPE': [mape] })\n",
    "results = pd.concat([results, tempResults])\n",
    "results = results[['Method', 'RMSE', 'MAPE']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcast into the future 12 months\n",
    "model= SARIMAX(snp['S&P'], order = (3, 1, 4), seasonal_order =(1,1,1, 12))\n",
    "result = model.fit()\n",
    "  \n",
    "\n",
    "# Forecast for the next 12 months\n",
    "forecast_snp = result.predict(start = len(snp), \n",
    "                          end = (len(snp)-1) + 1 * 12, \n",
    "                          typ = 'levels').rename('Forecast')\n",
    "  \n",
    "# Plot the forecast values\n",
    "plt.figure(figsize=(12,4))\n",
    "train['S&P'].plot(figsize = (12, 5), legend = True,label='Train')\n",
    "test['S&P'].plot(figsize = (12, 5), legend = True,label='Test')\n",
    "forecast_snp.plot(legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_snp.plot(legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Portfolio Return Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##lets put all the future forecasted values in the dateframe for analysis\n",
    "future_return_johnson = forecast_johnson.to_frame(name='Johnson & Johnson')\n",
    "future_return_merck = forecast_merck.to_frame(name='Merck')\n",
    "future_return_apple = forecast_apple.to_frame(name='Apple')\n",
    "future_return_google = forecast_google.to_frame(name='Google')\n",
    "future_return_market = forecast_snp.to_frame(name='S&P')\n",
    "\n",
    "##creating a new data frame for all the projected prices of stock\n",
    "frames = [future_return_johnson,future_return_merck,future_return_apple,future_return_google,future_return_market]\n",
    "future_returns = pd.concat(frames,axis=1)\n",
    "future_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets visualize the future forecasted prices\n",
    "future_returns['Johnson & Johnson'].plot(label = 'JnJ',figsize = (20,10))\n",
    "future_returns['Merck'].plot(label = 'Merck')\n",
    "future_returns['Google'].plot(label = 'Google')\n",
    "future_returns['Apple'].plot(label = 'Apple')\n",
    "future_returns['S&P'].plot(label = 'S&P')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Forecasted Adj Close Price')\n",
    "plt.title('Portfolio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the daily return from each stock \n",
    "\n",
    "return_stocks = future_returns.pct_change()\n",
    "return_stocks\n",
    "\n",
    "return_stocks = return_stocks.dropna(axis=0)\n",
    "return_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_stocks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##performance measures for future prices\n",
    "final_portfolio_stocks = return_stocks.describe().T\n",
    "final_portfolio_stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the redundant columns\n",
    "final_portfolio_stocks.drop(columns=['count','25%','75%'],inplace=True)\n",
    "\n",
    "final_portfolio_stocks.rename(columns={'50%':'median','mean':'avg daily return','std':'risk'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the annulized return\n",
    "final_portfolio_stocks['annualized return'] = final_portfolio_stocks['avg daily return']*252\n",
    "final_portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the annulaized risk\n",
    "final_portfolio_stocks['annualized risk'] = final_portfolio_stocks['risk']* np.sqrt(252)\n",
    "final_portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "plt.xticks(rotation=90)\n",
    "color = 'tab:green'\n",
    "ax1.set_title('Annualized Return vs Risk', fontsize=16)\n",
    "ax1.set_xlabel('Stocks', fontsize=16)\n",
    "ax1.set_ylabel('Annualized Return', fontsize=16, color=color)\n",
    "ax2 = sns.barplot(x=final_portfolio_stocks.index, y='annualized return', data = final_portfolio_stocks, palette='summer')\n",
    "ax1.tick_params(axis='y')\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('annualized risk', fontsize=16, color=color)\n",
    "ax2 = sns.lineplot(x=final_portfolio_stocks.index,y='annualized risk', data = final_portfolio_stocks, sort=False, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_portfolio = return_stocks[['Johnson & Johnson','Merck','Apple','Google']]\n",
    "my_portfolio.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weight = np.array([0.25, 0.25, 0.25,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns_Portfolio_mean =  my_portfolio.mean()\n",
    "print(daily_returns_Portfolio_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio daily returns\n",
    "my_portfolio['Portfolio_Daily_Return'] = my_portfolio.dot(initial_weight)\n",
    "\n",
    "my_portfolio.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_portfolio['Portfolio_Daily_Return'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative return from the portfolio\n",
    "Cumulative_returns_daily = (1+my_portfolio).cumprod()\n",
    "Cumulative_returns_daily.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Portfolio Return = Weighted average of return from each stock\n",
    "allocated_daily_returns = (initial_weight * daily_returns_Portfolio_mean)\n",
    "portfolio_return = np.sum(allocated_daily_returns)\n",
    "print(portfolio_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "Cumulative_returns_daily['Portfolio_Daily_Return'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix for the portfolio\n",
    "\n",
    "# Removing the last column (Portfolio_Daily_Return) from our calculation.\n",
    "covariance_portfolio = my_portfolio.iloc[:,:-1]\n",
    "covariance_portfolio = (covariance_portfolio.cov())*252\n",
    "\n",
    "covariance_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the matrix operations mentioned in the image above\n",
    "portfolio_variance = np.dot(initial_weight.T,np.dot(covariance_portfolio, initial_weight))\n",
    "print(\"------portfolio_variance------\",portfolio_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation (risk of portfolio)\n",
    "portfolio_risk = np.sqrt(portfolio_variance)\n",
    "portfolio_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the risk free rate is zero\n",
    "Sharpe_Ratio = my_portfolio['Portfolio_Daily_Return'].mean() / my_portfolio['Portfolio_Daily_Return'].std()\n",
    "Sharpe_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Annualised_Sharpe_Ratio = (252**0.5)*Sharpe_Ratio\n",
    "Annualised_Sharpe_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(return_stocks['S&P'], return_stocks['Johnson & Johnson'], 1)\n",
    "beta\n",
    "alpha\n",
    "rf = 0.75\n",
    "rm = return_stocks['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected_future_returns_portfolio = pd.DataFrame({'Stocks':'Johnson & Johnson','Expected Return':[er]})\n",
    "Expected_future_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(return_stocks['S&P'], return_stocks['Merck'], 1)\n",
    "beta\n",
    "rf = 0.75\n",
    "rm = return_stocks['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Merck','Expected Return':[er]})\n",
    "frames = [Expected_future_returns_portfolio,temp]\n",
    "Expected_future_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_future_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(return_stocks['S&P'], return_stocks['Apple'], 1)\n",
    "beta\n",
    "rf = 0.75\n",
    "rm = return_stocks['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Apple','Expected Return':[er]})\n",
    "frames = [Expected_future_returns_portfolio,temp]\n",
    "Expected_future_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_future_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Equation\n",
    "beta, alpha = np.polyfit(return_stocks['S&P'], return_stocks['Google'], 1)\n",
    "beta\n",
    "rf = 0.75\n",
    "rm = return_stocks['S&P'].mean() * 252\n",
    "er = rf + beta*(rm-rf)\n",
    "er\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame({'Stocks':'Google','Expected Return':[er]})\n",
    "frames = [Expected_future_returns_portfolio,temp]\n",
    "Expected_future_returns_portfolio = pd.concat(frames,axis=0)\n",
    "Expected_future_returns_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the market return\n",
    "#expected return\n",
    "rf = 0.75\n",
    "rm = return_stocks['S&P'].mean() * 252\n",
    "#er = rf + beta*(rm-rf)\n",
    "#er\n",
    "rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erp = Expected_future_returns_portfolio['Expected Return'].tolist()\n",
    "erp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##portfolio return\n",
    "my_portfolio = return_stocks[['Johnson & Johnson','Merck','Apple','Google']]\n",
    "my_portfolio.head()\n",
    "initial_weight = np.array([0.25, 0.25, 0.25,0.25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ER_portfolio_all = round(sum(erp * initial_weight),3)\n",
    "print('Expected Return Based on CAPM for the portfolio  is {}%\\n'.format(ER_portfolio_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation\n",
    " - Equal weightage is given to technology stocks and pharmaceutical stocks as we get suitable return with a minumum risk.\n",
    " - The weightage are 50 percent each to appple and google stocks and 50 percent to Johnson & Johnson, Merck.\n",
    " - We can switch our inital weightage according to the market run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
